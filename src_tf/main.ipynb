{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "validation_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reference_model = keras.Sequential(\n",
    "  [\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "  ],\n",
    "  name='reference'\n",
    ")\n",
    "\n",
    "reference_model.compile(\n",
    "  optimizer=keras.optimizers.Adam(0.001),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "reference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/temma/ghq/xai-model-optimazation/.venv/lib/python3.11/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 22s 51ms/step - loss: 0.3623 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.0807 - val_sparse_categorical_accuracy: 0.9782\n",
      "Epoch 2/6\n",
      "422/422 [==============================] - 21s 49ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.0563 - val_sparse_categorical_accuracy: 0.9852\n",
      "Epoch 3/6\n",
      "422/422 [==============================] - 23s 54ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0476 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 4/6\n",
      "422/422 [==============================] - 21s 50ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.0433 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 5/6\n",
      "422/422 [==============================] - 24s 57ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 6/6\n",
      "422/422 [==============================] - 22s 51ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0365 - val_sparse_categorical_accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 18:49:55.790295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 18:49:55.997899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple/assets\n"
     ]
    }
   ],
   "source": [
    "reference_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=batch_size,\n",
    "  epochs=6,\n",
    "  validation_split=validation_split,\n",
    ")\n",
    "\n",
    "reference_model.save('reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference test accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "_, reference_model_accuracy = reference_model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Reference test accuracy:', reference_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 13, 13, 32)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 5, 5, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,242\n",
      "Trainable params: 431,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "  [\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(10),\n",
    "  ],\n",
    "  name='baseline',\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(0.001),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "422/422 [==============================] - 16s 37ms/step - loss: 0.2551 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.0692 - val_sparse_categorical_accuracy: 0.9798\n",
      "Epoch 2/6\n",
      "422/422 [==============================] - 19s 44ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0525 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 3/6\n",
      "422/422 [==============================] - 22s 52ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.0483 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 4/6\n",
      "422/422 [==============================] - 23s 54ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 5/6\n",
      "422/422 [==============================] - 27s 64ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0374 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 6/6\n",
      "422/422 [==============================] - 27s 64ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0353 - val_sparse_categorical_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: baseline/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: baseline/assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=batch_size,\n",
    "  epochs=6,\n",
    "  validation_split=validation_split,\n",
    ")\n",
    "\n",
    "model.save('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9916999936103821\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pruned\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d_  (None, 26, 26, 32)       610       \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_average  (None, 13, 13, 32)       1         \n",
      " _pooling2d_4 (PruneLowMagni                                     \n",
      " tude)                                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 11, 11, 64)       36930     \n",
      " 5 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_average  (None, 5, 5, 64)         1         \n",
      " _pooling2d_5 (PruneLowMagni                                     \n",
      " tude)                                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 1600)             1         \n",
      " _2 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_4  (None, 256)              819458    \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_5  (None, 10)               5132      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 862,133\n",
      "Trainable params: 431,242\n",
      "Non-trainable params: 430,891\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from turtle import mode\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "epochs = 2\n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "  'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.80, begin_step=0, end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "model_for_pruning._name = 'pruned'\n",
    "\n",
    "model_for_pruning.compile(\n",
    "  optimizer=keras.optimizers.Adam(0.001),\n",
    "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 27s 56ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0413 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 25s 60ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned/assets\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split, \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_pruning.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "model_for_pruning.save('pruned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9916999936103821\n",
      "Pruned test accuracy: 0.9909999966621399\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "\n",
    "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
    "            # The magnitudes of the gradients produced by the soft targets scale\n",
    "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
    "            distillation_loss = (\n",
    "                self.distillation_loss_fn(\n",
    "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "                )\n",
    "                * self.temperature**2\n",
    "            )\n",
    "\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"distilled\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 13, 13, 8)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 16)        1168      \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                25664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,562\n",
      "Trainable params: 27,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_distillation = keras.models.Sequential(\n",
    "  [\n",
    "    keras.layers.Conv2D(32 / 4, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    keras.layers.Conv2D(64 / 4, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256 / 4, activation='relu'),\n",
    "    keras.layers.Dense(10),\n",
    "  ],\n",
    "  name='distilled',\n",
    ")\n",
    "\n",
    "model_for_distillation.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model_for_distillation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 49s 26ms/step - sparse_categorical_accuracy: 0.9209 - student_loss: 0.2505 - distillation_loss: 2.6163\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 50s 27ms/step - sparse_categorical_accuracy: 0.9808 - student_loss: 0.0592 - distillation_loss: 0.4214\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 44s 24ms/step - sparse_categorical_accuracy: 0.9853 - student_loss: 0.0453 - distillation_loss: 0.2789\n",
      "313/313 [==============================] - 3s 9ms/step - sparse_categorical_accuracy: 0.9848 - student_loss: 0.0426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9847999811172485, 0.00040756131056696177]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=model_for_distillation, teacher=model)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "model_for_distillation.save('distilled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9916999936103821\n",
      "Pruned test accuracy: 0.9909999966621399\n",
      "Distilled test accuracy: 0.9847999811172485\n"
     ]
    }
   ],
   "source": [
    "_, model_for_distillation_accuracy = model_for_distillation.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)\n",
    "print('Distilled test accuracy:', model_for_distillation_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
